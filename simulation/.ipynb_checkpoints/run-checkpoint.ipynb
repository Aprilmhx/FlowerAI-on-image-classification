{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5103e21d",
   "metadata": {},
   "source": [
    "# GPUs testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9178257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "device = torch.cuda.current_device()\n",
    "cuda = torch.device(\"cuda:0\")\n",
    "print(torch.cuda.nccl.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6a5bab",
   "metadata": {},
   "source": [
    "# Federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83dcda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8408758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegression(solver=\"liblinear\").fit(X, y)\n",
    "out = roc_auc_score(y, clf.predict_proba(X), multi_class='ovr') #(150,),(150,3)\n",
    "print(\"y\", print(type(y)))\n",
    "print(\"clf_X\", print(type(out)))\n",
    "print(\"out\", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd08b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes: int) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.input_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(self.input_features, num_classes)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x \n",
    "    \n",
    "a = Net(3)\n",
    "simu_in = torch.randn(4, 3, 224, 224)\n",
    "print(a(simu_in).shape)\n",
    "\n",
    "params_dict = zip(a.state_dict().keys(), parameters)\n",
    "state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "a.load_state_dict(state_dict, strict=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b1c0e",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e676b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocessing/divide_class.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf97752",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocessing/generate_json.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "\n",
    "def allocate_data_dirichlet(labels, num_classes, num_clients, alpha, train_ratio, val_ratio, test_ratio):\n",
    "    \"\"\"\n",
    "    Allocate data to clients using Dirichlet distribution.\n",
    "    \n",
    "    :param labels: Array of data labels.\n",
    "    :param num_clients: Number of clients to distribute data across.\n",
    "    :param alpha: Concentration parameter for the Dirichlet distribution.\n",
    "    :return: A list of indices for each client representing their data.\n",
    "    \"\"\"                                  \n",
    "    # Generating proportions for each class across clients\n",
    "    class_proportions = np.random.dirichlet([alpha]*num_clients, num_classes)  #[[0.2 0.8],[0.1 0.9],[0.5 0.5]]\n",
    "    client_data_indices = [[[],[],[]] for _ in range(num_clients)]                     #[[] []]\n",
    "    for class_label in range(num_classes):\n",
    "        sub_dict = labels[class_label]        \n",
    "        sub_dict = list(sub_dict.items())\n",
    "        random.shuffle(sub_dict)\n",
    "        proportions = class_proportions[class_label]                           #[0.2 0.8]\n",
    "        allocations = np.round(proportions * len(sub_dict)).astype(int)\n",
    "        # Ensure that rounding doesn't cause more allocations than available samples\n",
    "        allocations[-1] = len(sub_dict) - np.sum(allocations[:-1])        #[2 3]\n",
    "        print(\"allocations\", allocations)\n",
    "        # Allocate data based on calculated proportions\n",
    "        start = 0\n",
    "        #print(sub_dict)\n",
    "        for client_id, allocation in enumerate(allocations):                   #client_id=0|allocation=2            \n",
    "            client_data_indices[client_id][0].extend(sub_dict[start:(start+round(allocation*train_ratio))])\n",
    "            client_data_indices[client_id][1].extend(sub_dict[(start+round(allocation*train_ratio)):(start+round(allocation*(train_ratio+val_ratio)))])\n",
    "            client_data_indices[client_id][2].extend(sub_dict[(start+round(allocation*(train_ratio+val_ratio))):(start+allocation)])\n",
    "            start += allocation\n",
    "            \n",
    "    return client_data_indices\n",
    "\n",
    "file_list = []\n",
    "num_classes = 3\n",
    "num_clients = 2\n",
    "alpha = 1.5\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "for cls in range(num_classes):\n",
    "    file_dict = {}\n",
    "    files = [s.split(\".\")[0] for s in os.listdir(os.path.join(\"isic2017\",str(cls))) if '.jpg' in s]\n",
    "    for file in files:\n",
    "        file_dict[file] = cls\n",
    "    file_list.append(file_dict)\n",
    "\n",
    "clients = allocate_data_dirichlet(file_list, num_classes, num_clients, alpha, train_ratio, val_ratio, test_ratio)\n",
    "\n",
    "json_data = {}\n",
    "for num in range(num_clients):\n",
    "    json_data[\"client \"+str(num+1)] = {}\n",
    "    json_data[\"client \"+str(num+1)][\"train\"] = []\n",
    "    json_data[\"client \"+str(num+1)][\"val\"] = []\n",
    "    json_data[\"client \"+str(num+1)][\"test\"] = []\n",
    "    \n",
    "    print(\"train_len\", len(clients[num][0]))\n",
    "    print(\"val_len\", len(clients[num][1]))\n",
    "    print(\"test_len\", len(clients[num][2]))\n",
    "    \n",
    "    for (name, _) in clients[num][0]: \n",
    "        json_data[\"client \"+str(num+1)][\"train\"].append(str(name)+\".jpg\")\n",
    "    for (name, _) in clients[num][1]: \n",
    "        json_data[\"client \"+str(num+1)][\"val\"].append(str(name)+\".jpg\")\n",
    "    for (name, _) in clients[num][2]: \n",
    "        json_data[\"client \"+str(num+1)][\"test\"].append(str(name)+\".jpg\")        \n",
    "\n",
    "with open(\"FL_divide.json\", 'w') as file:\n",
    "    json.dump(json_data, file, indent=4)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b8175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "  \n",
    "arr = np.array([]) \n",
    "#arr = np.hstack((arr, np.array(['G', 'F', 'G']))) \n",
    "print(arr.size) \n",
    "  \n",
    "arr = np.vstack((arr, np.array(['G', 'F', 'G']))) \n",
    "print(arr.shape) \n",
    "arr = np.vstack((arr, np.array(['G', 'F', 'G']))) \n",
    "print(arr.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv = open(\"isic2019/ISIC_2019_Training_GroundTruth.csv\").read().splitlines()\n",
    "file_dict = {}\n",
    "for line in read_csv[1:]:\n",
    "    filename,MEL,NV,BCC,AK,BKL,DF,VASC,SCC,UNK = line.strip().split(\",\") \n",
    "    if UNK == \"0.0\":\n",
    "        print(\"!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355baddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
